{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "idT5Gen_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hHTQaV3nQXsy",
        "outputId": "d0ad4a82-7f3a-4e1f-ea64-c87eee955326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.4.2\n",
            "  Downloading transformers-4.4.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 26.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (4.64.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 44.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (4.11.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (1.21.6)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 43.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.4.2) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.4.2) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.4.2) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.2) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.2) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.2) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=80399bcf0a27f366682a50f49c2d4649868db35164196c769c3d5af67f9fff13\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.4.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 16.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets==1.5.0\n",
            "  Downloading datasets-1.5.0-py3-none-any.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 25.8 MB/s \n",
            "\u001b[?25hCollecting tqdm<4.50.0,>=4.27\n",
            "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.5.0) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.5.0) (0.3.5.1)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.5.0) (4.11.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.5.0) (1.3.5)\n",
            "Collecting huggingface-hub<0.1.0\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.5.0) (6.0.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.5.0) (0.70.13)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 62.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.5.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.5.0) (4.2.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.5.0) (3.13)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.5.0) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.5.0) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub<0.1.0->datasets==1.5.0) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.5.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.5.0) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.5.0) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.5.0) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.5.0) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.5.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.5.0) (1.15.0)\n",
            "Installing collected packages: tqdm, xxhash, huggingface-hub, fsspec, datasets\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.0\n",
            "    Uninstalling tqdm-4.64.0:\n",
            "      Successfully uninstalled tqdm-4.64.0\n",
            "Successfully installed datasets-1.5.0 fsspec-2022.5.0 huggingface-hub-0.0.19 tqdm-4.49.0 xxhash-3.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nlp==0.4.0\n",
            "  Downloading nlp-0.4.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 26.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (4.49.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (3.7.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (3.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (0.3.5.1)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (6.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp==0.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp==0.4.0) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp==0.4.0) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nlp==0.4.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nlp==0.4.0) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->nlp==0.4.0) (1.15.0)\n",
            "Installing collected packages: nlp\n",
            "Successfully installed nlp-0.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.4.2\n",
        "!pip install sentencepiece==0.1.95\n",
        "!pip install datasets==1.5.0\n",
        "!pip install nlp==0.4.0\n",
        "!pip install nltk\n",
        "!python -m nltk.downloader punkt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My Drive/Colab Notebooks/QG_idt5_t5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7yfBMPXuUsGj",
        "outputId": "c5ad91a9-7402-4a10-aeb9-479fd7c52143"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Colab Notebooks/QG_idt5_t5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd multitask-question-generation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FWBk3XjsVcPt",
        "outputId": "a0b76216-b5ef-46a4-be7d-d45c494d7347"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/QG_idt5_t5/multitask-question-generation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Data"
      ],
      "metadata": {
        "id": "xveWu9_mVlw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python prepare_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IgOkpvUVkhM",
        "outputId": "bd9688db-a532-401b-c4ac-94e31db80af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: 100% 756k/756k [00:00<00:00, 6.51MB/s]\n",
            "Downloading: 100% 65.0/65.0 [00:00<00:00, 50.3kB/s]\n",
            "Downloading: 100% 173/173 [00:00<00:00, 132kB/s]\n",
            "100% 65698/65698 [00:02<00:00, 30573.80it/s]\n",
            "06/07/2022 06:24:11 - INFO - nlp.arrow_writer -   Done writing 65698 examples in 51501866 bytes .\n",
            "100% 65698/65698 [00:02<00:00, 27268.16it/s]\n",
            "06/07/2022 06:24:14 - INFO - nlp.arrow_writer -   Done writing 65698 examples in 50875718 bytes .\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:175: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated eos tokens being added.\"\n",
            "100% 66/66 [01:56<00:00,  1.76s/it]\n",
            "06/07/2022 06:26:10 - INFO - nlp.arrow_writer -   Done writing 65698 examples in 631909622 bytes .\n",
            "100% 15881/15881 [00:00<00:00, 32311.61it/s]\n",
            "06/07/2022 06:26:11 - INFO - nlp.arrow_writer -   Done writing 15881 examples in 15426713 bytes .\n",
            "100% 15881/15881 [00:00<00:00, 29923.77it/s]\n",
            "06/07/2022 06:26:11 - INFO - nlp.arrow_writer -   Done writing 15881 examples in 15272801 bytes .\n",
            "100% 16/16 [00:28<00:00,  1.80s/it]\n",
            "06/07/2022 06:26:40 - INFO - nlp.arrow_writer -   Done writing 15881 examples in 155724557 bytes .\n",
            "06/07/2022 06:26:40 - INFO - nlp.arrow_dataset -   Set __getitem__(key) output type to torch for ['source_ids', 'target_ids', 'attention_mask'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "06/07/2022 06:26:40 - INFO - nlp.arrow_dataset -   Set __getitem__(key) output type to torch for ['source_ids', 'target_ids', 'attention_mask'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "06/07/2022 06:26:57 - INFO - __main__ -   saved train dataset at data/train_data_multitask_t5.pt\n",
            "06/07/2022 06:26:59 - INFO - __main__ -   saved validation dataset at data/valid_data_multitask_t5.pt\n",
            "06/07/2022 06:26:59 - INFO - __main__ -   saved tokenizer at t5_qg_tokenizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine Tune"
      ],
      "metadata": {
        "id": "GmZZ51R7VndI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 run_multi.py \\\n",
        "    --model_name_or_path muchad/idt5-base \\\n",
        "    --model_type t5 \\\n",
        "    --tokenizer_name_or_path t5_qg_tokenizer \\\n",
        "    --output_dir t5-base-multi \\\n",
        "    --train_file_path data/train_data_multitask_t5.pt \\\n",
        "    --valid_file_path data/valid_data_multitask_t5.pt \\\n",
        "    --per_device_train_batch_size 2 \\\n",
        "    --per_device_eval_batch_size 2 \\\n",
        "    --gradient_accumulation_steps 2 \\\n",
        "    --learning_rate 1e-4 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --seed 42 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --logging_steps 100 \\\n",
        "    --prediction_loss_only True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQy2b-4fGRZs",
        "outputId": "cee57d94-d1a5-46a6-d3b2-a72d482e3261"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06/07/2022 06:50:02 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "06/07/2022 06:50:02 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=t5-base-multi, overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=True, per_device_train_batch_size=2, per_device_eval_batch_size=2, gradient_accumulation_steps=2, eval_accumulation_steps=None, learning_rate=0.0001, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs/Jun07_06-50-02_27efe21eebd8, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=100, save_strategy=IntervalStrategy.STEPS, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=100, dataloader_num_workers=0, past_index=-1, run_name=t5-base-multi, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, _n_gpu=1)\n",
            "Downloading: 100% 742/742 [00:00<00:00, 748kB/s]\n",
            "Downloading: 100% 977M/977M [00:32<00:00, 29.8MB/s]\n",
            "06/07/2022 06:50:43 - INFO - __main__ -   loading dataset\n",
            "06/07/2022 06:50:48 - INFO - nlp.utils.file_utils -   PyTorch version 1.11.0+cu113 available.\n",
            "06/07/2022 06:50:48 - INFO - nlp.utils.file_utils -   TensorFlow version 2.8.2 available.\n",
            "06/07/2022 06:50:50 - INFO - __main__ -   finished loading dataset\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:836: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  FutureWarning,\n",
            "{'loss': 9.8336, 'learning_rate': 9.939113492450074e-05, 'epoch': 0.01}\n",
            "{'loss': 4.1212, 'learning_rate': 9.878226984900147e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5095, 'learning_rate': 9.81734047735022e-05, 'epoch': 0.02}\n",
            "{'loss': 3.1479, 'learning_rate': 9.756453969800294e-05, 'epoch': 0.02}\n",
            "{'loss': 2.8425, 'learning_rate': 9.695567462250366e-05, 'epoch': 0.03}\n",
            "{'loss': 2.7336, 'learning_rate': 9.634680954700439e-05, 'epoch': 0.04}\n",
            "{'loss': 2.6341, 'learning_rate': 9.573794447150511e-05, 'epoch': 0.04}\n",
            "{'loss': 2.5454, 'learning_rate': 9.512907939600585e-05, 'epoch': 0.05}\n",
            "{'loss': 2.3966, 'learning_rate': 9.452021432050658e-05, 'epoch': 0.05}\n",
            "{'loss': 2.3878, 'learning_rate': 9.39113492450073e-05, 'epoch': 0.06}\n",
            "{'loss': 2.4153, 'learning_rate': 9.330248416950804e-05, 'epoch': 0.07}\n",
            "{'loss': 2.2525, 'learning_rate': 9.269361909400878e-05, 'epoch': 0.07}\n",
            "{'loss': 2.2872, 'learning_rate': 9.20847540185095e-05, 'epoch': 0.08}\n",
            "{'loss': 2.3056, 'learning_rate': 9.147588894301024e-05, 'epoch': 0.09}\n",
            "{'loss': 2.2354, 'learning_rate': 9.086702386751096e-05, 'epoch': 0.09}\n",
            "{'loss': 2.13, 'learning_rate': 9.025815879201169e-05, 'epoch': 0.1}\n",
            "{'loss': 2.1767, 'learning_rate': 8.964929371651242e-05, 'epoch': 0.1}\n",
            "{'loss': 2.085, 'learning_rate': 8.904042864101315e-05, 'epoch': 0.11}\n",
            "{'loss': 2.1161, 'learning_rate': 8.843156356551388e-05, 'epoch': 0.12}\n",
            "{'loss': 2.1281, 'learning_rate': 8.782269849001462e-05, 'epoch': 0.12}\n",
            "{'loss': 2.1273, 'learning_rate': 8.721383341451534e-05, 'epoch': 0.13}\n",
            "{'loss': 1.9333, 'learning_rate': 8.660496833901608e-05, 'epoch': 0.13}\n",
            "{'loss': 1.9855, 'learning_rate': 8.599610326351682e-05, 'epoch': 0.14}\n",
            "{'loss': 2.0514, 'learning_rate': 8.538723818801754e-05, 'epoch': 0.15}\n",
            "{'loss': 1.8763, 'learning_rate': 8.477837311251828e-05, 'epoch': 0.15}\n",
            "{'loss': 2.034, 'learning_rate': 8.4169508037019e-05, 'epoch': 0.16}\n",
            "{'loss': 2.0019, 'learning_rate': 8.356064296151973e-05, 'epoch': 0.16}\n",
            "{'loss': 2.021, 'learning_rate': 8.295177788602046e-05, 'epoch': 0.17}\n",
            "{'loss': 1.789, 'learning_rate': 8.234291281052119e-05, 'epoch': 0.18}\n",
            "{'loss': 1.96, 'learning_rate': 8.173404773502192e-05, 'epoch': 0.18}\n",
            "{'loss': 1.9506, 'learning_rate': 8.112518265952266e-05, 'epoch': 0.19}\n",
            "{'loss': 1.9945, 'learning_rate': 8.051631758402338e-05, 'epoch': 0.19}\n",
            "{'loss': 1.8489, 'learning_rate': 7.990745250852412e-05, 'epoch': 0.2}\n",
            "{'loss': 1.9609, 'learning_rate': 7.929858743302484e-05, 'epoch': 0.21}\n",
            "{'loss': 1.8114, 'learning_rate': 7.868972235752558e-05, 'epoch': 0.21}\n",
            "{'loss': 1.7775, 'learning_rate': 7.80808572820263e-05, 'epoch': 0.22}\n",
            "{'loss': 1.8727, 'learning_rate': 7.747199220652703e-05, 'epoch': 0.23}\n",
            "{'loss': 1.8581, 'learning_rate': 7.686312713102776e-05, 'epoch': 0.23}\n",
            "{'loss': 1.6463, 'learning_rate': 7.62542620555285e-05, 'epoch': 0.24}\n",
            "{'loss': 1.881, 'learning_rate': 7.564539698002922e-05, 'epoch': 0.24}\n",
            "{'loss': 1.792, 'learning_rate': 7.503653190452996e-05, 'epoch': 0.25}\n",
            "{'loss': 1.7774, 'learning_rate': 7.44276668290307e-05, 'epoch': 0.26}\n",
            "{'loss': 1.8227, 'learning_rate': 7.381880175353142e-05, 'epoch': 0.26}\n",
            "{'loss': 1.8181, 'learning_rate': 7.320993667803216e-05, 'epoch': 0.27}\n",
            "{'loss': 1.8273, 'learning_rate': 7.260107160253288e-05, 'epoch': 0.27}\n",
            "{'loss': 1.7356, 'learning_rate': 7.199220652703362e-05, 'epoch': 0.28}\n",
            "{'loss': 1.7883, 'learning_rate': 7.138334145153434e-05, 'epoch': 0.29}\n",
            "{'loss': 1.7773, 'learning_rate': 7.077447637603507e-05, 'epoch': 0.29}\n",
            "{'loss': 1.6832, 'learning_rate': 7.01656113005358e-05, 'epoch': 0.3}\n",
            "{'loss': 1.7564, 'learning_rate': 6.955674622503654e-05, 'epoch': 0.3}\n",
            "{'loss': 1.7352, 'learning_rate': 6.894788114953726e-05, 'epoch': 0.31}\n",
            "{'loss': 1.7035, 'learning_rate': 6.8339016074038e-05, 'epoch': 0.32}\n",
            "{'loss': 1.6742, 'learning_rate': 6.773015099853872e-05, 'epoch': 0.32}\n",
            "{'loss': 1.6448, 'learning_rate': 6.712128592303946e-05, 'epoch': 0.33}\n",
            "{'loss': 1.6668, 'learning_rate': 6.65124208475402e-05, 'epoch': 0.33}\n",
            "{'loss': 1.6993, 'learning_rate': 6.590355577204092e-05, 'epoch': 0.34}\n",
            "{'loss': 1.7446, 'learning_rate': 6.529469069654164e-05, 'epoch': 0.35}\n",
            "{'loss': 1.7443, 'learning_rate': 6.468582562104238e-05, 'epoch': 0.35}\n",
            "{'loss': 1.6161, 'learning_rate': 6.40769605455431e-05, 'epoch': 0.36}\n",
            "{'loss': 1.7379, 'learning_rate': 6.346809547004384e-05, 'epoch': 0.37}\n",
            "{'loss': 1.6924, 'learning_rate': 6.285923039454458e-05, 'epoch': 0.37}\n",
            "{'loss': 1.7112, 'learning_rate': 6.22503653190453e-05, 'epoch': 0.38}\n",
            "{'loss': 1.6929, 'learning_rate': 6.164150024354604e-05, 'epoch': 0.38}\n",
            "{'loss': 1.7251, 'learning_rate': 6.103263516804676e-05, 'epoch': 0.39}\n",
            "{'loss': 1.6462, 'learning_rate': 6.042377009254749e-05, 'epoch': 0.4}\n",
            "{'loss': 1.7141, 'learning_rate': 5.981490501704823e-05, 'epoch': 0.4}\n",
            "{'loss': 1.7135, 'learning_rate': 5.920603994154895e-05, 'epoch': 0.41}\n",
            "{'loss': 1.603, 'learning_rate': 5.859717486604969e-05, 'epoch': 0.41}\n",
            "{'loss': 1.5225, 'learning_rate': 5.798830979055042e-05, 'epoch': 0.42}\n",
            "{'loss': 1.6124, 'learning_rate': 5.737944471505114e-05, 'epoch': 0.43}\n",
            "{'loss': 1.6131, 'learning_rate': 5.677057963955188e-05, 'epoch': 0.43}\n",
            "{'loss': 1.7406, 'learning_rate': 5.61617145640526e-05, 'epoch': 0.44}\n",
            "{'loss': 1.7881, 'learning_rate': 5.555284948855334e-05, 'epoch': 0.44}\n",
            "{'loss': 1.6207, 'learning_rate': 5.4943984413054076e-05, 'epoch': 0.45}\n",
            "{'loss': 1.724, 'learning_rate': 5.43351193375548e-05, 'epoch': 0.46}\n",
            "{'loss': 1.556, 'learning_rate': 5.372625426205553e-05, 'epoch': 0.46}\n",
            "{'loss': 1.4865, 'learning_rate': 5.3117389186556266e-05, 'epoch': 0.47}\n",
            "{'loss': 1.5853, 'learning_rate': 5.250852411105699e-05, 'epoch': 0.47}\n",
            "{'loss': 1.767, 'learning_rate': 5.1899659035557727e-05, 'epoch': 0.48}\n",
            "{'loss': 1.52, 'learning_rate': 5.129079396005846e-05, 'epoch': 0.49}\n",
            "{'loss': 1.6042, 'learning_rate': 5.068192888455918e-05, 'epoch': 0.49}\n",
            "{'loss': 1.644, 'learning_rate': 5.007306380905992e-05, 'epoch': 0.5}\n",
            "{'loss': 1.6946, 'learning_rate': 4.946419873356065e-05, 'epoch': 0.51}\n",
            "{'loss': 1.4956, 'learning_rate': 4.885533365806138e-05, 'epoch': 0.51}\n",
            "{'loss': 1.6989, 'learning_rate': 4.824646858256211e-05, 'epoch': 0.52}\n",
            "{'loss': 1.6555, 'learning_rate': 4.763760350706284e-05, 'epoch': 0.52}\n",
            "{'loss': 1.6311, 'learning_rate': 4.702873843156357e-05, 'epoch': 0.53}\n",
            "{'loss': 1.599, 'learning_rate': 4.64198733560643e-05, 'epoch': 0.54}\n",
            "{'loss': 1.5566, 'learning_rate': 4.581100828056503e-05, 'epoch': 0.54}\n",
            "{'loss': 1.6407, 'learning_rate': 4.520214320506576e-05, 'epoch': 0.55}\n",
            "{'loss': 1.6029, 'learning_rate': 4.459327812956649e-05, 'epoch': 0.55}\n",
            "{'loss': 1.6163, 'learning_rate': 4.398441305406722e-05, 'epoch': 0.56}\n",
            "{'loss': 1.6081, 'learning_rate': 4.3375547978567955e-05, 'epoch': 0.57}\n",
            "{'loss': 1.4802, 'learning_rate': 4.2766682903068685e-05, 'epoch': 0.57}\n",
            "{'loss': 1.5369, 'learning_rate': 4.2157817827569416e-05, 'epoch': 0.58}\n",
            "{'loss': 1.6204, 'learning_rate': 4.154895275207014e-05, 'epoch': 0.58}\n",
            "{'loss': 1.4668, 'learning_rate': 4.0940087676570876e-05, 'epoch': 0.59}\n",
            "{'loss': 1.594, 'learning_rate': 4.0331222601071606e-05, 'epoch': 0.6}\n",
            "{'loss': 1.5247, 'learning_rate': 3.9722357525572336e-05, 'epoch': 0.6}\n",
            "{'loss': 1.5738, 'learning_rate': 3.9113492450073066e-05, 'epoch': 0.61}\n",
            "{'loss': 1.5452, 'learning_rate': 3.8504627374573796e-05, 'epoch': 0.61}\n",
            "{'loss': 1.5752, 'learning_rate': 3.7895762299074527e-05, 'epoch': 0.62}\n",
            "{'loss': 1.5462, 'learning_rate': 3.728689722357526e-05, 'epoch': 0.63}\n",
            "{'loss': 1.5436, 'learning_rate': 3.667803214807599e-05, 'epoch': 0.63}\n",
            "{'loss': 1.5684, 'learning_rate': 3.6069167072576724e-05, 'epoch': 0.64}\n",
            "{'loss': 1.4688, 'learning_rate': 3.546030199707745e-05, 'epoch': 0.65}\n",
            "{'loss': 1.5335, 'learning_rate': 3.485143692157818e-05, 'epoch': 0.65}\n",
            "{'loss': 1.5311, 'learning_rate': 3.424257184607891e-05, 'epoch': 0.66}\n",
            "{'loss': 1.5425, 'learning_rate': 3.3633706770579644e-05, 'epoch': 0.66}\n",
            "{'loss': 1.5512, 'learning_rate': 3.3024841695080374e-05, 'epoch': 0.67}\n",
            "{'loss': 1.5343, 'learning_rate': 3.24159766195811e-05, 'epoch': 0.68}\n",
            "{'loss': 1.5302, 'learning_rate': 3.1807111544081835e-05, 'epoch': 0.68}\n",
            "{'loss': 1.527, 'learning_rate': 3.1198246468582565e-05, 'epoch': 0.69}\n",
            "{'loss': 1.5781, 'learning_rate': 3.0589381393083295e-05, 'epoch': 0.69}\n",
            "{'loss': 1.5601, 'learning_rate': 2.9980516317584022e-05, 'epoch': 0.7}\n",
            "{'loss': 1.4368, 'learning_rate': 2.937165124208476e-05, 'epoch': 0.71}\n",
            "{'loss': 1.4486, 'learning_rate': 2.8762786166585485e-05, 'epoch': 0.71}\n",
            "{'loss': 1.4322, 'learning_rate': 2.8153921091086216e-05, 'epoch': 0.72}\n",
            "{'loss': 1.481, 'learning_rate': 2.7545056015586946e-05, 'epoch': 0.72}\n",
            "{'loss': 1.4885, 'learning_rate': 2.693619094008768e-05, 'epoch': 0.73}\n",
            "{'loss': 1.5076, 'learning_rate': 2.632732586458841e-05, 'epoch': 0.74}\n",
            "{'loss': 1.5746, 'learning_rate': 2.571846078908914e-05, 'epoch': 0.74}\n",
            "{'loss': 1.5396, 'learning_rate': 2.5109595713589866e-05, 'epoch': 0.75}\n",
            "{'loss': 1.4918, 'learning_rate': 2.45007306380906e-05, 'epoch': 0.75}\n",
            "{'loss': 1.4745, 'learning_rate': 2.389186556259133e-05, 'epoch': 0.76}\n",
            "{'loss': 1.5248, 'learning_rate': 2.328300048709206e-05, 'epoch': 0.77}\n",
            "{'loss': 1.5183, 'learning_rate': 2.2674135411592794e-05, 'epoch': 0.77}\n",
            "{'loss': 1.5173, 'learning_rate': 2.206527033609352e-05, 'epoch': 0.78}\n",
            "{'loss': 1.5127, 'learning_rate': 2.1456405260594254e-05, 'epoch': 0.79}\n",
            "{'loss': 1.5461, 'learning_rate': 2.0847540185094984e-05, 'epoch': 0.79}\n",
            "{'loss': 1.4756, 'learning_rate': 2.0238675109595714e-05, 'epoch': 0.8}\n",
            "{'loss': 1.519, 'learning_rate': 1.9629810034096448e-05, 'epoch': 0.8}\n",
            "{'loss': 1.5065, 'learning_rate': 1.9020944958597174e-05, 'epoch': 0.81}\n",
            "{'loss': 1.4654, 'learning_rate': 1.8412079883097908e-05, 'epoch': 0.82}\n",
            "{'loss': 1.529, 'learning_rate': 1.7803214807598638e-05, 'epoch': 0.82}\n",
            "{'loss': 1.4518, 'learning_rate': 1.7194349732099368e-05, 'epoch': 0.83}\n",
            "{'loss': 1.4785, 'learning_rate': 1.65854846566001e-05, 'epoch': 0.83}\n",
            "{'loss': 1.5447, 'learning_rate': 1.597661958110083e-05, 'epoch': 0.84}\n",
            "{'loss': 1.4575, 'learning_rate': 1.536775450560156e-05, 'epoch': 0.85}\n",
            "{'loss': 1.4862, 'learning_rate': 1.475888943010229e-05, 'epoch': 0.85}\n",
            "{'loss': 1.4519, 'learning_rate': 1.4150024354603019e-05, 'epoch': 0.86}\n",
            "{'loss': 1.4128, 'learning_rate': 1.3541159279103752e-05, 'epoch': 0.86}\n",
            "{'loss': 1.4907, 'learning_rate': 1.2932294203604481e-05, 'epoch': 0.87}\n",
            "{'loss': 1.5517, 'learning_rate': 1.2323429128105213e-05, 'epoch': 0.88}\n",
            "{'loss': 1.4504, 'learning_rate': 1.1714564052605943e-05, 'epoch': 0.88}\n",
            "{'loss': 1.5439, 'learning_rate': 1.1105698977106673e-05, 'epoch': 0.89}\n",
            "{'loss': 1.3915, 'learning_rate': 1.0496833901607405e-05, 'epoch': 0.9}\n",
            "{'loss': 1.4462, 'learning_rate': 9.887968826108135e-06, 'epoch': 0.9}\n",
            "{'loss': 1.4622, 'learning_rate': 9.279103750608865e-06, 'epoch': 0.91}\n",
            "{'loss': 1.4536, 'learning_rate': 8.670238675109595e-06, 'epoch': 0.91}\n",
            "{'loss': 1.6105, 'learning_rate': 8.061373599610327e-06, 'epoch': 0.92}\n",
            "{'loss': 1.4436, 'learning_rate': 7.452508524111057e-06, 'epoch': 0.93}\n",
            "{'loss': 1.4108, 'learning_rate': 6.843643448611787e-06, 'epoch': 0.93}\n",
            "{'loss': 1.5413, 'learning_rate': 6.234778373112518e-06, 'epoch': 0.94}\n",
            "{'loss': 1.4576, 'learning_rate': 5.625913297613249e-06, 'epoch': 0.94}\n",
            "{'loss': 1.4612, 'learning_rate': 5.0170482221139795e-06, 'epoch': 0.95}\n",
            "{'loss': 1.404, 'learning_rate': 4.4081831466147105e-06, 'epoch': 0.96}\n",
            "{'loss': 1.4885, 'learning_rate': 3.799318071115441e-06, 'epoch': 0.96}\n",
            "{'loss': 1.4437, 'learning_rate': 3.1904529956161716e-06, 'epoch': 0.97}\n",
            "{'loss': 1.5903, 'learning_rate': 2.581587920116902e-06, 'epoch': 0.97}\n",
            "{'loss': 1.3788, 'learning_rate': 1.9727228446176328e-06, 'epoch': 0.98}\n",
            "{'loss': 1.3862, 'learning_rate': 1.3638577691183635e-06, 'epoch': 0.99}\n",
            "{'loss': 1.4535, 'learning_rate': 7.549926936190941e-07, 'epoch': 0.99}\n",
            "{'loss': 1.5313, 'learning_rate': 1.4612761811982466e-07, 'epoch': 1.0}\n",
            "{'train_runtime': 7429.5386, 'train_samples_per_second': 2.211, 'epoch': 1.0}\n",
            "100% 16424/16424 [2:03:49<00:00,  2.21it/s]\n",
            "06/07/2022 08:55:00 - INFO - __main__ -   *** Evaluate ***\n",
            "100% 7941/7941 [07:44<00:00, 17.09it/s]\n",
            "06/07/2022 09:02:45 - INFO - __main__ -   ***** Eval results *****\n",
            "06/07/2022 09:02:45 - INFO - __main__ -     epoch = 1.0\n",
            "06/07/2022 09:02:45 - INFO - __main__ -     eval_loss = 1.3961185216903687\n",
            "06/07/2022 09:02:45 - INFO - __main__ -     eval_mem_cpu_alloc_delta = 79139\n",
            "06/07/2022 09:02:45 - INFO - __main__ -     eval_mem_cpu_peaked_delta = 736570\n",
            "06/07/2022 09:02:45 - INFO - __main__ -     eval_mem_gpu_alloc_delta = 0\n",
            "06/07/2022 09:02:45 - INFO - __main__ -     eval_mem_gpu_peaked_delta = 114355200\n",
            "06/07/2022 09:02:45 - INFO - __main__ -     eval_runtime = 464.6383\n",
            "06/07/2022 09:02:45 - INFO - __main__ -     eval_samples_per_second = 34.179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKpfotMTfeXU",
        "outputId": "cba31892-32fe-4ea8-cd58-a6bd9b806fe3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.49.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pipelines import pipeline\n",
        "pipe = pipeline(\"multitask-qa-qg\", model = \"t5-base-multi\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "V4fG2qwTk2Y7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18237896-ff6a-4ca8-ccf2-288a94b517fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"Pangeran Harya Dipanegara (atau biasa dikenal dengan nama Pangeran Diponegoro, lahir di Ngayogyakarta Hadiningrat, 11 November 1785 – meninggal di Makassar, Hindia Belanda, 8 Januari 1855 pada umur 69 tahun) adalah salah seorang pahlawan nasional Republik Indonesia, yang memimpin Perang Diponegoro atau Perang Jawa selama periode tahun 1825 hingga 1830 melawan pemerintah Hindia Belanda. Sejarah mencatat, Perang Diponegoro atau Perang Jawa dikenal sebagai perang yang menelan korban terbanyak dalam sejarah Indonesia, yakni 8.000 korban serdadu Hindia Belanda, 7.000 pribumi, dan 200 ribu orang Jawa serta kerugian materi 25 juta Gulden.\""
      ],
      "metadata": {
        "id": "JzpJ7gLfl1c_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4IY1C1Ol5RQ",
        "outputId": "b08aca30-ef7f-4adf-efd1-6b7368c0c168"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1764: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  next_indices = next_tokens // vocab_size\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'answer': 'Pangeran Harya Dipanegara',\n",
              "  'question': 'Siapa yang memimpin Perang Diponegoro atau Perang Jawa selama periode tahun 1825 hingga 1830?'},\n",
              " {'answer': '25 juta',\n",
              "  'question': 'Berapa banyak orang yang kerugian dari Perang Diponegoro atau Perang Jawa?'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = \"Pemerintah berencana menaikkan tiket Candi Borobudur menjadi Rp 750.000/orang. Kenaikan harga tiket ini bertujuan untuk membatasi jumlah pengunjung sehingga kondisi candi sebagai cagar budaya tetap ini tetap lestari. Namun, harga tiket yang mencapai Rp 750.000 per orang itu bukanlah tiket masuk, melainkan tiket naik ke atas Candi Borobudur. Direktur Utama PT Aviasi Pariwisata Indonesia (Persero)/InJourney, Dony Oskaria menyebut tiket masuk Candi Borobudur tak berubah.\"\n",
        "pipe(text2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3M8AYItjNcX",
        "outputId": "dda14c71-e254-421c-d819-5aeb87deaa70"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1764: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  next_indices = next_tokens // vocab_size\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'answer': '750.000/orang',\n",
              "  'question': 'Berapa harga tiket masuk ke Candi Borobudur?'},\n",
              " {'answer': 'cagar budaya',\n",
              "  'question': 'Selain tiket masuk, kondisi apa yang tetap tetap lestari?'},\n",
              " {'answer': 'tiket masuk',\n",
              "  'question': 'Apa yang dimaksud dengan tiket naik ke atas Candi Borobudur?'},\n",
              " {'answer': 'Dony Oskaria',\n",
              "  'question': 'Siapa yang menyebut tiket masuk Candi Borobudur tak berubah?'}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe({\"context\":text1,\"question\":\"kapan pangeran diponegoro lahir?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PKZF-fGgjpPN",
        "outputId": "f73f2978-53fa-480a-d02c-ff960567a001"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'11 November 1785'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe({\"context\":text1,\"question\":\"kapan pangeran diponegoro meninggal?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SfwrlPA7j5ot",
        "outputId": "876256f3-81b3-4577-b3df-42b5016d0e35"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'8 Januari 1855'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe({\"context\":text2,\"question\":\"berapa harga tiket candi borobudur?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S4U2eMrSkDSq",
        "outputId": "e1786720-60a9-4b72-d105-5c277f1d3ea8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'750.000'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe({\"context\":text2,\"question\":\"siapa itu dony oskaria?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4rB55PwLkTk1",
        "outputId": "dfbee978-fa14-4e51-8d21-b4a8c9409b7b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Direktur Utama'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe({\"context\":text2,\"question\":\"apa tujuan kenaikan harga tiket?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "o1tYjPVbkhGD",
        "outputId": "be24b99c-8db0-4c2b-b8cb-ccd462851ec7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'membatasi jumlah pengunjung sehingga kondisi candi sebagai cagar budaya tetap ini tetap lestari'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe({\"context\":text2,\"question\":\"siapa nama direktur?\"})"
      ],
      "metadata": {
        "id": "47vYLKbHkocy",
        "outputId": "95d7dedc-924c-4575-83b9-9a356c8c5475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dony Oskaria'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}