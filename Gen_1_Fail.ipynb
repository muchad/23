{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gen_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1gYwDSBxu4Tivb7F60p7nTks49G6-PtYj",
      "authorship_tag": "ABX9TyPwaRM3tdr0xsXNeMyw7qvn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muchad/23/blob/main/Gen_1_Fail.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hHTQaV3nQXsy",
        "outputId": "79c95bce-a4f2-48e2-cf09-761546647e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.4.2\n",
            "  Downloading transformers-4.4.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 32.8 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (3.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (4.64.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (4.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.4.2) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.4.2) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.4.2) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.2) (2022.5.18.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.2) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=09c8b1d216ff8849d10c044c20527e1c26ca76ad97b25f5dbbf2f0a63ba7c6bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.4.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 31.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets==1.5.0\n",
            "  Downloading datasets-1.5.0-py3-none-any.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 30.4 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 62.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.5.0) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.5.0) (0.70.13)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 72.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.5.0) (0.3.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.5.0) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.5.0) (1.21.6)\n",
            "Collecting tqdm<4.50.0,>=4.27\n",
            "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.5.0) (4.11.4)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.5.0) (6.0.1)\n",
            "Collecting huggingface-hub<0.1.0\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.5.0) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.5.0) (4.2.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.5.0) (3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.5.0) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub<0.1.0->datasets==1.5.0) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.5.0) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.5.0) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.5.0) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.5.0) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.5.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.5.0) (1.15.0)\n",
            "Installing collected packages: tqdm, xxhash, huggingface-hub, fsspec, datasets\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.0\n",
            "    Uninstalling tqdm-4.64.0:\n",
            "      Successfully uninstalled tqdm-4.64.0\n",
            "Successfully installed datasets-1.5.0 fsspec-2022.5.0 huggingface-hub-0.0.19 tqdm-4.49.0 xxhash-3.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nlp==0.4.0\n",
            "  Downloading nlp-0.4.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 27.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (3.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (0.3.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (4.49.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (3.7.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (2.23.0)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from nlp==0.4.0) (6.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp==0.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp==0.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp==0.4.0) (2022.5.18.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nlp==0.4.0) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nlp==0.4.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->nlp==0.4.0) (1.15.0)\n",
            "Installing collected packages: nlp\n",
            "Successfully installed nlp-0.4.0\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.4.2\n",
        "!pip install sentencepiece==0.1.95\n",
        "!pip install datasets==1.5.0\n",
        "!pip install nlp==0.4.0\n",
        "!python -m nltk.downloader punkt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My Drive/Colab Notebooks/QG_id_mt5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7yfBMPXuUsGj",
        "outputId": "a775ff91-0567-4c0f-c0a1-e2690156a7b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Colab Notebooks/QG_id_mt5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ozcangundes/multitask-question-generation.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "himLb10NTxWL",
        "outputId": "2c478bb1-f623-4603-e614-7fc9bfe99700"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'multitask-question-generation'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 50 (delta 21), reused 25 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (50/50), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd multitask-question-generation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FWBk3XjsVcPt",
        "outputId": "5927b527-e29e-449d-f07c-d3f8b1be38f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/QG_id_mt5/multitask-question-generation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Data"
      ],
      "metadata": {
        "id": "xveWu9_mVlw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 prepare_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IgOkpvUVkhM",
        "outputId": "ff33b1f6-681b-41fa-a5c5-9061b9f4aa51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: 100% 4.31M/4.31M [00:01<00:00, 2.80MB/s]\n",
            "Downloading: 100% 99.0/99.0 [00:00<00:00, 87.1kB/s]\n",
            "Downloading: 100% 82.0/82.0 [00:00<00:00, 70.0kB/s]\n",
            "100% 323920/323920 [00:08<00:00, 37475.94it/s]\n",
            "06/04/2022 13:42:15 - INFO - nlp.arrow_writer -   Done writing 323920 examples in 295430510 bytes .\n",
            "100% 323920/323920 [00:14<00:00, 22578.69it/s]\n",
            "06/04/2022 13:42:30 - INFO - nlp.arrow_writer -   Done writing 323920 examples in 292472456 bytes .\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:175: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated eos tokens being added.\"\n",
            "100% 324/324 [08:00<00:00,  1.48s/it]\n",
            "06/04/2022 13:50:30 - INFO - nlp.arrow_writer -   Done writing 323920 examples in 3157224824 bytes .\n",
            "100% 28348/28348 [00:00<00:00, 36709.67it/s]\n",
            "06/04/2022 13:50:31 - INFO - nlp.arrow_writer -   Done writing 28348 examples in 27597219 bytes .\n",
            "100% 28348/28348 [00:00<00:00, 34090.79it/s]\n",
            "06/04/2022 13:50:32 - INFO - nlp.arrow_writer -   Done writing 28348 examples in 27346539 bytes .\n",
            "100% 29/29 [00:42<00:00,  1.47s/it]\n",
            "06/04/2022 13:51:15 - INFO - nlp.arrow_writer -   Done writing 28348 examples in 278056599 bytes .\n",
            "06/04/2022 13:51:15 - INFO - nlp.arrow_dataset -   Set __getitem__(key) output type to torch for ['source_ids', 'target_ids', 'attention_mask'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "06/04/2022 13:51:15 - INFO - nlp.arrow_dataset -   Set __getitem__(key) output type to torch for ['source_ids', 'target_ids', 'attention_mask'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "tcmalloc: large alloc 1264623616 bytes == 0x138fb6000 @  0x7f59f0dbc615 0x592b76 0x4df71e 0x59394f 0x5957cf 0x595b69 0x4e7b7e 0x4eb71e 0x4eb228 0x4e8dec 0x4ec4c2 0x4eb228 0x4e8dec 0x4ebe42 0x4eb967 0x44f8bc 0x4ec6bc 0x44f8ec 0x4eb228 0x4e8dec 0x4ebe42 0x4eb967 0x4eb228 0x4e8dec 0x4ebe42 0x4eb9b6 0x4eb228 0x4e8dec 0x4ebe42 0x4ec658 0x4e9074\n",
            "tcmalloc: large alloc 1580785664 bytes == 0x184dc0000 @  0x7f59f0dbc615 0x592b76 0x4df71e 0x59394f 0x5957cf 0x595b69 0x4e7b7e 0x4eb71e 0x4eb228 0x4e8dec 0x4ec4c2 0x4eb228 0x4e8dec 0x4ebe42 0x4eb967 0x44f8bc 0x4ec6bc 0x44f8ec 0x4eb228 0x4e8dec 0x4ebe42 0x4eb932 0x4eb228 0x4e8dec 0x4ebe42 0x4eb9b6 0x4eb228 0x4e8dec 0x4ebe42 0x4ec658 0x4e9074\n",
            "tcmalloc: large alloc 1975984128 bytes == 0x1e314e000 @  0x7f59f0dbc615 0x592b76 0x4df71e 0x59394f 0x5957cf 0x595b69 0x4e7b7e 0x4eb71e 0x4eb228 0x4e8dec 0x4ec4c2 0x4eb228 0x4e8dec 0x4ebe42 0x4eb967 0x44f8bc 0x4ec6bc 0x44f8ec 0x4eb228 0x4e8dec 0x4ebe42 0x4eb9b6 0x4eb228 0x4e8dec 0x4ebe42 0x4eb9b6 0x4eb228 0x4e8dec 0x4ebe42 0x4ec658 0x4e9074\n",
            "tcmalloc: large alloc 2469986304 bytes == 0x258dc0000 @  0x7f59f0dbc615 0x592b76 0x4df71e 0x59394f 0x5957cf 0x595b69 0x4e7b7e 0x4eb71e 0x4eb228 0x4e8dec 0x4ec4c2 0x4eb228 0x4e8dec 0x4ebe42 0x4eb967 0x44f8bc 0x4ec6bc 0x44f8ec 0x4eb228 0x4e8dec 0x4ebe42 0x4eb967 0x4eb228 0x4e8dec 0x4ebe42 0x4eb9dc 0x4eb228 0x4e8dec 0x4ebe42 0x4ec658 0x4e9074\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine Tune"
      ],
      "metadata": {
        "id": "GmZZ51R7VndI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from run_multi import run_multi\n",
        "\n",
        "args_dict = {\n",
        "    \"model_name_or_path\": \"google/mt5-small\",\n",
        "    \"model_type\": \"mt5\",\n",
        "    \"tokenizer_name_or_path\": \"mt5_qg_tokenizer\",\n",
        "    \"output_dir\": \"multi\",\n",
        "    \"train_file_path\": \"data/train_data_multitask_mt5.pt\",\n",
        "    \"valid_file_path\": \"data/valid_data_multitask_mt5.pt\",\n",
        "    \"per_device_train_batch_size\": 16,\n",
        "    \"per_device_eval_batch_size\": 16,\n",
        "    \"gradient_accumulation_steps\": 2,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"num_train_epochs\": 2,\n",
        "    \"seed\": 42,\n",
        "    \"do_train\": True,\n",
        "    \"do_eval\": True,\n",
        "    \"evaluate_during_training\": True,\n",
        "    \"logging_steps\": 100\n",
        "}\n",
        "\n",
        "# start training\n",
        "run_multi(args_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jpaDMNJdVoh1",
        "outputId": "2de633db-d860-450d-8226-71696b509f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05/30/2022 00:20:02 - WARNING - run_multi -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
            "05/30/2022 00:20:02 - INFO - run_multi -   Training/evaluation parameters TrainingArguments(output_dir=multi, overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=16, gradient_accumulation_steps=2, eval_accumulation_steps=None, learning_rate=0.0001, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs/May30_00-20-02_8b0b7f8ffec1, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=100, save_strategy=IntervalStrategy.STEPS, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=100, dataloader_num_workers=0, past_index=-1, run_name=multi, disable_tqdm=False, remove_unused_columns=False, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, _n_gpu=0)\n",
            "05/30/2022 00:20:20 - INFO - run_multi -   loading dataset\n",
            "05/30/2022 00:20:22 - INFO - run_multi -   finished loading dataset\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:836: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pipelines import pipeline\n",
        "pipe = pipeline(\"question-generation\", model = \"t5-small-qg-hl\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "V4fG2qwTk2Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text4 = \"Forrest Gump is a 1994 American comedy-drama film directed by Robert Zemeckis and written by Eric Roth. \\\n",
        "It is based on the 1986 novel of the same name by Winston Groom and stars Tom Hanks, Robin Wright, Gary Sinise, \\\n",
        "Mykelti Williamson and Sally Field. The story depicts several decades in the life of Forrest Gump (Hanks), \\\n",
        "a slow-witted but kind-hearted man from Alabama who witnesses and unwittingly influences several defining \\\n",
        "historical events in the 20th century United States. The film differs substantially from the novel.\""
      ],
      "metadata": {
        "id": "JzpJ7gLfl1c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(text4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t4IY1C1Ol5RQ",
        "outputId": "38e2101a-343c-43cc-ce9a-d9b9d8652e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}